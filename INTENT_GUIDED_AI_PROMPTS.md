# Intent-Guided AI Prompts

## Overview

The AI layer uses intent-specific system prompts to generate contextual responses. Each detected intent has tailored instructions that guide the AI's behavior and response style.

## Prompt Structure

### Two-Part Prompt System

1. **System Prompt** - Intent-specific instructions (guides AI behavior)
2. **User Prompt** - Original user message (what the user said)

```
System Prompt (Intent-Specific)
    â†“
AI Processing
    â†“
User Prompt (Original Message)
    â†“
AI-Generated Response
```

## Intent-Specific System Prompts

### 1. Pricing Intent (`MessageIntent.PRICING`)

**System Prompt:**
```
You are a helpful customer service assistant for a SaaS platform.
When users ask about pricing, provide helpful information about pricing plans and options.
Be informative, friendly, and encourage them to learn more about features and benefits.
Do not make up specific prices - focus on value and options available.
```

**AI Behavior:**
- Provides pricing-related information
- Focuses on value and options
- Encourages learning about features
- Does NOT invent specific prices
- Friendly and informative tone

**Example Response:**
"I'd be happy to help you with pricing information! We offer flexible plans to suit different needs. Would you like to know more about our features and which plan might work best for you?"

---

### 2. Greeting Intent (`MessageIntent.GREETING`)

**System Prompt:**
```
You are a friendly and professional customer service assistant.
When users greet you, respond warmly and politely. Welcome them and offer assistance.
Keep responses concise and inviting.
```

**AI Behavior:**
- Responds warmly and politely
- Welcomes the user
- Offers assistance
- Keeps responses concise
- Inviting and friendly tone

**Example Response:**
"Hello! ðŸ‘‹ Welcome! I'm here to help. How can I assist you today?"

---

### 3. Other Intent (`MessageIntent.OTHER`)

**System Prompt:**
```
You are a helpful customer service assistant.
When user intent is unclear, ask clarifying questions to understand what they need.
Be friendly, patient, and guide the conversation to help the user.
```

**AI Behavior:**
- Asks clarifying questions
- Tries to understand user needs
- Guides the conversation
- Friendly and patient tone
- Helps user express their needs

**Example Response:**
"Thanks for reaching out! Could you tell me a bit more about what you're looking for? I want to make sure I can help you in the best way possible."

---

## Why Intent-Guided Prompts?

### 1. **Contextual Responses**
- AI knows what the user wants (intent)
- Can tailor response style and content
- More relevant and helpful responses

### 2. **Consistent Behavior**
- Same intent = consistent response style
- Predictable AI behavior
- Better user experience

### 3. **Easy to Enhance**
- Can refine prompts per intent independently
- Add new intents with their own prompts
- A/B test different prompt strategies

### 4. **No Hardcoded Content**
- All responses generated by AI
- No static text in code
- Dynamic and contextual

### 5. **Ready for LLM Integration**
- Prompt structure matches LLM APIs
- Easy to plug in OpenAI, Anthropic, etc.
- Just replace placeholder with API call

## Implementation Flow

```python
# 1. Detect intent
intent = detect_intent(message)  # â†’ MessageIntent.PRICING

# 2. Build intent-specific system prompt
system_prompt = build_system_prompt(intent)
# â†’ "You are a helpful customer service assistant for a SaaS platform..."

# 3. Build user prompt
user_prompt = build_user_prompt(message)
# â†’ "What's the price?"

# 4. Generate AI response (with LLM)
response = await llm_client.chat(
    system=system_prompt,
    user=user_prompt
)
# â†’ "I'd be happy to help you with pricing information..."
```

## Benefits

âœ… **Intent-Aware** - AI knows what user wants
âœ… **Contextual** - Responses match user intent
âœ… **Flexible** - Easy to adjust prompts per intent
âœ… **Scalable** - Add new intents easily
âœ… **No Hardcoding** - All content from AI
âœ… **LLM-Ready** - Structure matches API requirements

## Future Enhancement

When integrating actual LLM (OpenAI, Anthropic, etc.):

```python
async def generate_ai_response(message, intent):
    system_prompt = build_system_prompt(intent)
    user_prompt = build_user_prompt(message)
    
    # Replace placeholder with actual LLM call
    response = await openai_client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )
    
    return response.choices[0].message.content
```

**The prompt structure is ready - just add the API call!**

## Summary

Intent-guided prompts ensure:
- AI responses match user intent
- Consistent behavior per intent category
- Easy to enhance and customize
- Ready for LLM integration
- No hardcoded business logic

**The AI layer is now intent-aware and prompt-driven!**



