"""Dashboard API routes for analytics and data retrieval."""
import logging
from datetime import datetime, timedelta
from typing import List, Optional

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy import func, and_, or_
from sqlalchemy.orm import Session

from app.database import get_db
from app.models import Conversation, Lead, AnalyticsEvent, ChannelIntegration, User as UserModel, Message, ConversationMemory, KnowledgeEntry
from app.routes.auth import get_current_user

log = logging.getLogger(__name__)
router = APIRouter(prefix="/api/dashboard", tags=["dashboard"])


@router.get("/overview")
async def get_overview(
    days: int = Query(7, ge=1, le=365),
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get dashboard overview statistics with extended insights."""
    start_date = datetime.utcnow() - timedelta(days=days)
    last_24h = datetime.utcnow() - timedelta(hours=24)

    # Total conversations
    total_conversations = db.query(func.count(Conversation.id)).filter(
        Conversation.created_at >= start_date
    ).scalar() or 0

    # Active chats (conversations in last 24 hours)
    active_chats = db.query(func.count(Conversation.id)).filter(
        Conversation.created_at >= last_24h
    ).scalar() or 0

    # Leads captured
    total_leads = db.query(func.count(Lead.id)).filter(
        Lead.created_at >= start_date
    ).scalar() or 0

    # Most common intents
    intent_counts = (
        db.query(Conversation.intent, func.count(Conversation.id).label("count"))
        .filter(Conversation.created_at >= start_date)
        .group_by(Conversation.intent)
        .order_by(func.count(Conversation.id).desc())
        .limit(5)
        .all()
    )
    most_common_intents = [{"intent": intent, "count": count} for intent, count in intent_counts]

    # Channel distribution
    channel_counts = (
        db.query(Conversation.channel, func.count(Conversation.id).label("count"))
        .filter(Conversation.created_at >= start_date)
        .group_by(Conversation.channel)
        .all()
    )
    channel_distribution = [{"channel": channel, "count": count} for channel, count in channel_counts]

    # ========== NEW EXTENDED DATA ==========
    
    # System Health: AI engine status (always running for rule-based)
    # System Health: Fallback trigger rate (unknown intents)
    unknown_intent_count = db.query(func.count(Conversation.id)).filter(
        and_(Conversation.intent == "unknown", Conversation.created_at >= start_date)
    ).scalar() or 0
    fallback_rate = (unknown_intent_count / total_conversations * 100) if total_conversations > 0 else 0

    # System Health: Rule coverage (intents with responses vs missing)
    all_intents = db.query(Conversation.intent).filter(
        Conversation.created_at >= start_date
    ).distinct().all()
    covered_intents = [intent[0] for intent in all_intents if intent[0] and intent[0] != "unknown"]
    rule_coverage = len(covered_intents) / max(len(all_intents), 1) * 100 if all_intents else 100

    # System Health: Channel connectivity (active channels)
    active_channels = db.query(ChannelIntegration.channel).filter(
        ChannelIntegration.is_active == True
    ).distinct().all()
    channel_connectivity = len(active_channels)

    # Channel Performance Intelligence
    channel_performance = []
    for channel, count in channel_counts:
        channel_leads = db.query(func.count(Lead.id)).filter(
            and_(Lead.channel == channel, Lead.created_at >= start_date)
        ).scalar() or 0
        lead_rate = (channel_leads / count * 100) if count > 0 else 0
        
        # AI resolution rate (conversations that didn't escalate to human)
        # For now, assume all are AI-resolved (no human handoff tracking yet)
        ai_resolution_rate = 95.0  # Placeholder - can be enhanced later
        
        # Peak activity (hour with most messages)
        hour_counts = (
            db.query(func.extract('hour', Conversation.created_at).label("hour"), 
                    func.count(Conversation.id).label("count"))
            .filter(and_(Conversation.channel == channel, Conversation.created_at >= start_date))
            .group_by(func.extract('hour', Conversation.created_at))
            .order_by(func.count(Conversation.id).desc())
            .first()
        )
        peak_hour = int(hour_counts[0]) if hour_counts else None
        
        channel_performance.append({
            "channel": channel,
            "message_volume": count,
            "lead_capture_rate": round(lead_rate, 1),
            "ai_resolution_rate": round(ai_resolution_rate, 1),
            "peak_activity_hour": peak_hour,
        })

    # Intent Quality & Coverage
    intent_quality = []
    for intent, count in intent_counts:
        # Leads generated by this intent
        intent_leads = db.query(func.count(Lead.id)).filter(
            and_(Lead.source_intent == intent, Lead.created_at >= start_date)
        ).scalar() or 0
        
        # Fallback rate for this intent (if unknown)
        is_fallback = (intent == "unknown")
        
        intent_quality.append({
            "intent": intent,
            "count": count,
            "leads_generated": intent_leads,
            "is_fallback": is_fallback,
        })
    
    # Top performing intents (by lead generation)
    top_intents_by_leads = sorted(intent_quality, key=lambda x: x["leads_generated"], reverse=True)[:3]
    
    # Intents causing fallbacks
    fallback_intents = [iq for iq in intent_quality if iq["is_fallback"]]

    # Conversation Flow Funnel
    total_incoming = total_conversations
    ai_responses = total_conversations  # All conversations have AI responses
    # User engagement (conversations with multiple messages - simplified)
    engaged_conversations = db.query(func.count(func.distinct(Conversation.user_id))).filter(
        Conversation.created_at >= start_date
    ).scalar() or 0
    leads_captured = total_leads
    # Human handoff (placeholder - no tracking yet)
    human_handoffs = 0

    # Smart Alerts & Recommendations
    alerts = []
    if fallback_rate > 15:
        alerts.append({
            "type": "warning",
            "priority": "high",
            "title": "High Fallback Rate",
            "message": f"{round(fallback_rate, 1)}% of conversations are falling back to default responses. Consider adding intent rules.",
        })
    if rule_coverage < 80:
        alerts.append({
            "type": "info",
            "priority": "medium",
            "title": "Rule Coverage Gap",
            "message": f"Only {round(rule_coverage, 1)}% of detected intents have custom responses.",
        })
    # Channel underperforming
    if channel_performance:
        min_lead_rate = min(cp["lead_capture_rate"] for cp in channel_performance)
        underperforming = [cp for cp in channel_performance if cp["lead_capture_rate"] == min_lead_rate and min_lead_rate < 5]
        if underperforming:
            alerts.append({
                "type": "info",
                "priority": "medium",
                "title": "Channel Performance",
                "message": f"{underperforming[0]['channel']} has low lead capture rate ({min_lead_rate}%).",
            })

    # Recent Activity Timeline
    recent_leads = db.query(Lead).filter(
        Lead.created_at >= start_date
    ).order_by(Lead.created_at.desc()).limit(5).all()
    
    recent_events = []
    for lead in recent_leads:
        recent_events.append({
            "type": "lead",
            "title": f"New lead from {lead.channel}",
            "description": f"{lead.name or 'Anonymous'} - {lead.source_intent or 'unknown intent'}",
            "timestamp": lead.created_at.isoformat(),
        })
    
    # Add intent gap events (unknown intents)
    if unknown_intent_count > 0:
        recent_events.append({
            "type": "intent_gap",
            "title": "Intent Gap Detected",
            "description": f"{unknown_intent_count} conversations with unknown intent in the last {days} days",
            "timestamp": datetime.utcnow().isoformat(),
        })

    # Lead Snapshot Summary
    leads_today = db.query(func.count(Lead.id)).filter(
        func.date(Lead.created_at) == func.date(datetime.utcnow())
    ).scalar() or 0
    
    leads_this_week = db.query(func.count(Lead.id)).filter(
        Lead.created_at >= datetime.utcnow() - timedelta(days=7)
    ).scalar() or 0
    
    # Best performing channel for leads
    best_channel_leads = (
        db.query(Lead.channel, func.count(Lead.id).label("count"))
        .filter(Lead.created_at >= start_date)
        .group_by(Lead.channel)
        .order_by(func.count(Lead.id).desc())
        .first()
    )
    best_channel = best_channel_leads[0] if best_channel_leads else None
    
    # Top lead-generating intent
    top_lead_intent = (
        db.query(Lead.source_intent, func.count(Lead.id).label("count"))
        .filter(and_(Lead.created_at >= start_date, Lead.source_intent.isnot(None)))
        .group_by(Lead.source_intent)
        .order_by(func.count(Lead.id).desc())
        .first()
    )
    top_lead_intent_name = top_lead_intent[0] if top_lead_intent else None

    # Time-Based Performance Insights
    # Best performing hour
    hour_performance = (
        db.query(func.extract('hour', Conversation.created_at).label("hour"),
                func.count(Conversation.id).label("count"))
        .filter(Conversation.created_at >= start_date)
        .group_by(func.extract('hour', Conversation.created_at))
        .order_by(func.count(Conversation.id).desc())
        .first()
    )
    best_hour = int(hour_performance[0]) if hour_performance else None
    
    # Best performing day of week
    day_performance = (
        db.query(func.extract('dow', Conversation.created_at).label("day"),
                func.count(Conversation.id).label("count"))
        .filter(Conversation.created_at >= start_date)
        .group_by(func.extract('dow', Conversation.created_at))
        .order_by(func.count(Conversation.id).desc())
        .first()
    )
    best_day = int(day_performance[0]) if day_performance else None
    day_names = ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"]
    best_day_name = day_names[best_day] if best_day is not None else None

    return {
        # Existing data
        "total_conversations": total_conversations,
        "active_chats": active_chats,
        "leads_captured": total_leads,
        "most_common_intents": most_common_intents,
        "channel_distribution": channel_distribution,
        "period_days": days,
        # New extended data
        "system_health": {
            "ai_engine_status": "running",
            "rule_coverage_health": round(rule_coverage, 1),
            "fallback_trigger_rate": round(fallback_rate, 1),
            "channel_connectivity": channel_connectivity,
        },
        "channel_performance": channel_performance,
        "intent_quality": {
            "top_performing": top_intents_by_leads,
            "lead_generating": [iq for iq in intent_quality if iq["leads_generated"] > 0],
            "causing_fallbacks": fallback_intents,
        },
        "conversation_flow": {
            "incoming": total_incoming,
            "ai_responses": ai_responses,
            "user_engagement": engaged_conversations,
            "leads_captured": leads_captured,
            "human_handoffs": human_handoffs,
        },
        "alerts": alerts[:5],  # Limit to 5 most important
        "recent_activity": recent_events[:10],  # Limit to 10 most recent
        "lead_snapshot": {
            "leads_today": leads_today,
            "leads_this_week": leads_this_week,
            "best_channel": best_channel,
            "top_lead_intent": top_lead_intent_name,
        },
        "time_insights": {
            "best_hour": best_hour,
            "best_day": best_day_name,
        },
    }


@router.get("/conversations")
async def get_conversations(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    channel: Optional[str] = None,
    intent: Optional[str] = None,
    status: Optional[str] = None,  # ai-handled, human-assisted, escalated
    has_fallback: Optional[bool] = None,  # Filter by fallback status
    has_lead: Optional[bool] = None,  # Filter by lead potential
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get paginated conversations list with intelligence data."""
    query = db.query(Conversation)

    # Apply filters
    if channel:
        query = query.filter(Conversation.channel == channel)
    if intent:
        query = query.filter(Conversation.intent == intent)
    if has_fallback is not None:
        if has_fallback:
            query = query.filter(Conversation.intent == "unknown")
        else:
            query = query.filter(Conversation.intent != "unknown")
    if has_lead is not None:
        # Check if conversation has associated lead
        # Simplified approach: filter by user_ids that have leads
        lead_user_ids = db.query(Lead.user_id).distinct().all()
        lead_user_id_list = [uid[0] for uid in lead_user_ids] if lead_user_ids else []
        
        if has_lead:
            if lead_user_id_list:
                query = query.filter(Conversation.user_id.in_(lead_user_id_list))
            else:
                # No leads exist, return empty result
                query = query.filter(Conversation.id == -1)  # Impossible condition
        else:
            if lead_user_id_list:
                query = query.filter(~Conversation.user_id.in_(lead_user_id_list))

    # Get total count
    total = query.count()

    # Apply pagination
    offset = (page - 1) * limit
    conversations = query.order_by(Conversation.created_at.desc()).offset(offset).limit(limit).all()

    # Build response with intelligence data
    result_conversations = []
    for conv in conversations:
        # Get conversation memory for context
        memory = db.query(ConversationMemory).filter(
            ConversationMemory.user_id == conv.user_id,
            ConversationMemory.channel == conv.channel
        ).first()

        # Count messages for this conversation
        message_count = db.query(func.count(Message.id)).filter(
            Message.user_id == conv.user_id,
            Message.channel == conv.channel
        ).scalar() or 1

        # Check for associated lead
        lead = db.query(Lead).filter(
            Lead.user_id == conv.user_id,
            Lead.channel == conv.channel
        ).first()

        # Determine conversation status
        status_value = "ai-handled"  # Default - all are AI-handled in Phase 1
        if conv.intent == "unknown":
            status_value = "needs-attention"
        if lead:
            status_value = "lead-captured"

        # Calculate fallback count (unknown intents for this user)
        fallback_count = db.query(func.count(Conversation.id)).filter(
            Conversation.user_id == conv.user_id,
            Conversation.channel == conv.channel,
            Conversation.intent == "unknown"
        ).scalar() or 0

        # Generate smart labels
        labels = []
        if lead:
            labels.append("Lead Captured")
        if conv.intent == "pricing":
            labels.append("Pricing Inquiry")
        if conv.intent == "unknown":
            labels.append("Unresolved")
        if message_count > 3:
            labels.append("Repeat Customer")
        if lead and lead.status == "new":
            labels.append("High Intent")

        # Check for health indicators
        health_indicators = []
        if fallback_count > 2:
            health_indicators.append("repeated_fallbacks")
        if conv.intent == "unknown":
            health_indicators.append("unresolved_intent")

        result_conversations.append({
            "id": conv.id,
            "user_id": conv.user_id,
            "channel": conv.channel,
            "user_message": conv.user_message,
            "bot_reply": conv.bot_reply,
            "intent": conv.intent,
            "created_at": conv.created_at.isoformat(),
            # Extended intelligence data
            "status": status_value,
            "message_count": message_count,
            "fallback_count": fallback_count,
            "labels": labels,
            "health_indicators": health_indicators,
            "has_lead": lead is not None,
            "lead_id": lead.id if lead else None,
        })

    return {
        "conversations": result_conversations,
        "total": total,
        "page": page,
        "limit": limit,
        "total_pages": (total + limit - 1) // limit,
    }


@router.get("/knowledge")
async def get_knowledge_base(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    intent: Optional[str] = None,
    status: Optional[str] = None,  # active, inactive, needs-review
    search: Optional[str] = None,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get knowledge base entries with intelligence data."""
    from sqlalchemy import or_
    import json
    
    # For now, use default business_id (can be enhanced with multi-tenant later)
    default_business_id = 1
    
    query = db.query(KnowledgeEntry).filter(KnowledgeEntry.business_id == default_business_id)
    
    # Apply filters
    if intent:
        query = query.filter(KnowledgeEntry.intent == intent)
    if status == "active":
        query = query.filter(KnowledgeEntry.is_active == True)
    elif status == "inactive":
        query = query.filter(KnowledgeEntry.is_active == False)
    if search:
        query = query.filter(
            (KnowledgeEntry.question.ilike(f"%{search}%")) |
            (KnowledgeEntry.answer.ilike(f"%{search}%"))
        )
    
    # Get total count
    total = query.count()
    
    # Apply pagination
    offset = (page - 1) * limit
    entries = query.order_by(KnowledgeEntry.updated_at.desc()).offset(offset).limit(limit).all()
    
    # Get all intents from conversations
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Build response with intelligence data
    result_entries = []
    for entry in entries:
        # Count usage in conversations (simple keyword matching)
        usage_count = 0
        keywords = []
        if entry.keywords:
            try:
                keywords = json.loads(entry.keywords) if isinstance(entry.keywords, str) else entry.keywords
                if keywords and isinstance(keywords, list):
                    # Count conversations with matching keywords
                    usage_count = db.query(func.count(Conversation.id)).filter(
                        Conversation.created_at >= start_date,
                        or_(*[Conversation.user_message.ilike(f"%{kw}%") for kw in keywords[:3]])
                    ).scalar() or 0
            except:
                keywords = []
        
        # Check if entry is linked to intent
        has_intent_link = entry.intent is not None and entry.intent != ""
        
        # Determine quality signals
        quality_signals = []
        if usage_count > 10:
            quality_signals.append("high_performing")
        elif usage_count == 0:
            quality_signals.append("unused")
        if not has_intent_link:
            quality_signals.append("needs_intent_link")
        if entry.is_active == False:
            quality_signals.append("inactive")
        
        # Get last used timestamp (simplified - use updated_at for now)
        last_used = entry.updated_at.isoformat()
        
        result_entries.append({
            "id": entry.id,
            "question": entry.question,
            "answer": entry.answer,
            "keywords": keywords,
            "intent": entry.intent,
            "is_active": entry.is_active,
            "created_at": entry.created_at.isoformat(),
            "updated_at": entry.updated_at.isoformat(),
            # Intelligence data
            "usage_count": usage_count,
            "quality_signals": quality_signals,
            "has_intent_link": has_intent_link,
            "last_used": last_used,
        })
    
    return {
        "entries": result_entries,
        "total": total,
        "page": page,
        "limit": limit,
        "total_pages": (total + limit - 1) // limit,
    }


@router.get("/knowledge/health")
async def get_knowledge_health(
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get knowledge base health and coverage metrics."""
    default_business_id = 1
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Total knowledge entries
    total_entries = db.query(func.count(KnowledgeEntry.id)).filter(
        KnowledgeEntry.business_id == default_business_id
    ).scalar() or 0
    
    # Active entries
    active_entries = db.query(func.count(KnowledgeEntry.id)).filter(
        KnowledgeEntry.business_id == default_business_id,
        KnowledgeEntry.is_active == True
    ).scalar() or 0
    
    # Entries with intent links
    entries_with_intent = db.query(func.count(KnowledgeEntry.id)).filter(
        KnowledgeEntry.business_id == default_business_id,
        KnowledgeEntry.intent.isnot(None),
        KnowledgeEntry.intent != ""
    ).scalar() or 0
    
    # Get all intents from conversations
    conversation_intents = db.query(Conversation.intent).filter(
        Conversation.created_at >= start_date
    ).distinct().all()
    all_intents = [intent[0] for intent in conversation_intents if intent[0] and intent[0] != "unknown"]
    
    # Get intents with knowledge entries
    knowledge_intents = db.query(KnowledgeEntry.intent).filter(
        KnowledgeEntry.business_id == default_business_id,
        KnowledgeEntry.intent.isnot(None),
        KnowledgeEntry.intent != ""
    ).distinct().all()
    knowledge_intent_list = [intent[0] for intent in knowledge_intents]
    
    # Intents without knowledge
    intents_without_knowledge = [intent for intent in all_intents if intent not in knowledge_intent_list]
    
    return {
        "total_entries": total_entries,
        "active_entries": active_entries,
        "entries_with_intent": entries_with_intent,
        "intents_without_knowledge": intents_without_knowledge,
        "unused_entries_count": 0,  # Would need more complex logic
        "coverage_percentage": round((len(knowledge_intent_list) / max(len(all_intents), 1)) * 100, 1) if all_intents else 100,
    }


@router.get("/knowledge/mapping")
async def get_intent_knowledge_mapping(
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get intent to knowledge entry mapping."""
    default_business_id = 1
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Get all intents from conversations
    conversation_intents = db.query(Conversation.intent, func.count(Conversation.id).label("count")).filter(
        Conversation.created_at >= start_date
    ).group_by(Conversation.intent).all()
    
    # Get all knowledge entries
    knowledge_entries = db.query(KnowledgeEntry).filter(
        KnowledgeEntry.business_id == default_business_id
    ).all()
    
    # Build mapping
    mapping = []
    for intent, count in conversation_intents:
        if intent and intent != "unknown":
            linked_entries = [entry for entry in knowledge_entries if entry.intent == intent]
            mapping.append({
                "intent": intent,
                "conversation_count": count,
                "knowledge_entries": [
                    {
                        "id": entry.id,
                        "question": entry.question,
                        "is_active": entry.is_active,
                    }
                    for entry in linked_entries
                ],
                "has_coverage": len(linked_entries) > 0,
            })
    
    return {
        "mapping": mapping,
    }


@router.get("/knowledge/{entry_id}")
async def get_knowledge_entry_detail(
    entry_id: int,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get detailed knowledge entry with usage data."""
    default_business_id = 1
    from sqlalchemy import or_
    import json
    
    entry = db.query(KnowledgeEntry).filter(
        KnowledgeEntry.id == entry_id,
        KnowledgeEntry.business_id == default_business_id
    ).first()
    
    if not entry:
        raise HTTPException(status_code=404, detail="Knowledge entry not found")
    
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Get usage timeline
    keywords = []
    if entry.keywords:
        try:
            keywords = json.loads(entry.keywords) if isinstance(entry.keywords, str) else entry.keywords
        except:
            pass
    
    # Get conversations with matching keywords
    usage_timeline = []
    if keywords and isinstance(keywords, list):
        for keyword in keywords[:5]:
            conversations = db.query(Conversation).filter(
                Conversation.user_message.ilike(f"%{keyword}%"),
                Conversation.created_at >= start_date
            ).order_by(Conversation.created_at.desc()).limit(10).all()
            
            for conv in conversations:
                usage_timeline.append({
                    "type": "used_in_conversation",
                    "timestamp": conv.created_at.isoformat(),
                    "conversation_id": conv.id,
                    "user_message": conv.user_message[:100],
                    "matched_keyword": keyword,
                })
    
    # Sort by timestamp
    usage_timeline.sort(key=lambda x: x["timestamp"], reverse=True)
    
    return {
        "entry": {
            "id": entry.id,
            "question": entry.question,
            "answer": entry.answer,
            "keywords": keywords,
            "intent": entry.intent,
            "is_active": entry.is_active,
            "created_at": entry.created_at.isoformat(),
            "updated_at": entry.updated_at.isoformat(),
        },
        "usage_timeline": usage_timeline[:20],
    }


@router.get("/conversations/{conversation_id}")
async def get_conversation_detail(
    conversation_id: int,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get detailed conversation with full context, AI reasoning, and timeline."""
    conversation = db.query(Conversation).filter(Conversation.id == conversation_id).first()
    
    if not conversation:
        raise HTTPException(status_code=404, detail="Conversation not found")

    # Get all messages for this conversation
    messages = db.query(Message).filter(
        Message.user_id == conversation.user_id,
        Message.channel == conversation.channel
    ).order_by(Message.created_at.asc()).all()

    # Get conversation memory
    memory = db.query(ConversationMemory).filter(
        ConversationMemory.user_id == conversation.user_id,
        ConversationMemory.channel == conversation.channel
    ).first()

    # Get associated lead
    lead = db.query(Lead).filter(
        Lead.user_id == conversation.user_id,
        Lead.channel == conversation.channel
    ).first()

    # Get all conversations from this user for timeline
    all_user_conversations = db.query(Conversation).filter(
        Conversation.user_id == conversation.user_id,
        Conversation.channel == conversation.channel
    ).order_by(Conversation.created_at.asc()).all()

    # Count fallbacks
    fallback_count = db.query(func.count(Conversation.id)).filter(
        Conversation.user_id == conversation.user_id,
        Conversation.channel == conversation.channel,
        Conversation.intent == "unknown"
    ).scalar() or 0

    # Determine status
    status_value = "ai-handled"
    if conversation.intent == "unknown":
        status_value = "needs-attention"
    if lead:
        status_value = "lead-captured"

    # Build AI reasoning trace (rule-based)
    ai_reasoning = {
        "detected_intent": conversation.intent,
        "confidence": "high" if conversation.intent != "unknown" else "low",
        "intent_history": [{"intent": conv.intent, "timestamp": conv.created_at.isoformat()} for conv in all_user_conversations],
        "rules_matched": [conversation.intent] if conversation.intent != "unknown" else [],
        "knowledge_base_used": False,  # Can be enhanced later
        "fallback_reason": "Unknown intent detected" if conversation.intent == "unknown" else None,
        "context_used": {
            "last_intent": memory.last_intent if memory else None,
            "message_count": memory.message_count if memory else 0,
        }
    }

    # Build timeline with enhancements
    timeline = []
    for conv in all_user_conversations:
        timeline.append({
            "type": "conversation",
            "timestamp": conv.created_at.isoformat(),
            "intent": conv.intent,
            "user_message": conv.user_message[:100] + "..." if len(conv.user_message) > 100 else conv.user_message,
            "bot_reply": conv.bot_reply[:100] + "..." if len(conv.bot_reply) > 100 else conv.bot_reply,
            "is_fallback": conv.intent == "unknown",
        })

    # Add lead capture event if exists
    if lead:
        timeline.append({
            "type": "lead_capture",
            "timestamp": lead.created_at.isoformat(),
            "lead_id": lead.id,
            "source_intent": lead.source_intent,
        })

    # Sort timeline by timestamp
    timeline.sort(key=lambda x: x["timestamp"])

    # Health indicators
    health_indicators = []
    if fallback_count > 2:
        health_indicators.append({
            "type": "repeated_fallbacks",
            "severity": "warning",
            "message": f"{fallback_count} fallback responses detected",
        })
    if conversation.intent == "unknown":
        health_indicators.append({
            "type": "unresolved_intent",
            "severity": "info",
            "message": "Intent could not be determined",
        })

    return {
        "conversation": {
            "id": conversation.id,
            "user_id": conversation.user_id,
            "channel": conversation.channel,
            "user_message": conversation.user_message,
            "bot_reply": conversation.bot_reply,
            "intent": conversation.intent,
            "created_at": conversation.created_at.isoformat(),
        },
        "status": status_value,
        "intelligence": {
            "primary_intent": conversation.intent,
            "confidence": "high" if conversation.intent != "unknown" else "low",
            "fallback_count": fallback_count,
            "message_count": len(messages),
        },
        "ai_reasoning": ai_reasoning,
        "timeline": timeline,
        "health_indicators": health_indicators,
        "lead": {
            "id": lead.id,
            "name": lead.name,
            "email": lead.email,
            "phone": lead.phone,
            "status": lead.status,
            "source_intent": lead.source_intent,
            "created_at": lead.created_at.isoformat(),
        } if lead else None,
        "messages": [
            {
                "id": msg.id,
                "text": msg.message_text,
                "is_from_user": msg.is_from_user,
                "intent": msg.intent,
                "timestamp": msg.created_at.isoformat(),
            }
            for msg in messages
        ],
    }


@router.get("/analytics/intents")
async def get_intent_analytics(
    days: int = Query(30, ge=1, le=365),
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get intent analytics over time."""
    start_date = datetime.utcnow() - timedelta(days=days)

    # Intent frequency
    intent_data = (
        db.query(Conversation.intent, func.count(Conversation.id).label("count"))
        .filter(Conversation.created_at >= start_date)
        .group_by(Conversation.intent)
        .order_by(func.count(Conversation.id).desc())
        .all()
    )

    return {
        "intents": [{"intent": intent, "count": count} for intent, count in intent_data],
        "period_days": days,
    }


@router.get("/analytics/channels")
async def get_channel_analytics(
    days: int = Query(30, ge=1, le=365),
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get channel performance analytics."""
    start_date = datetime.utcnow() - timedelta(days=days)

    channel_data = (
        db.query(
            Conversation.channel,
            func.count(Conversation.id).label("total"),
            func.count(func.distinct(Conversation.user_id)).label("unique_users"),
        )
        .filter(Conversation.created_at >= start_date)
        .group_by(Conversation.channel)
        .all()
    )

    return {
        "channels": [
            {"channel": channel, "total_conversations": total, "unique_users": unique_users}
            for channel, total, unique_users in channel_data
        ],
        "period_days": days,
    }


@router.get("/analytics/timeline")
async def get_timeline_analytics(
    days: int = Query(7, ge=1, le=90),
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get conversation timeline data."""
    start_date = datetime.utcnow() - timedelta(days=days)

    # Group by day
    timeline_data = (
        db.query(
            func.date(Conversation.created_at).label("date"),
            func.count(Conversation.id).label("count"),
        )
        .filter(Conversation.created_at >= start_date)
        .group_by(func.date(Conversation.created_at))
        .order_by(func.date(Conversation.created_at))
        .all()
    )

    return {
        "timeline": [{"date": str(date), "count": count} for date, count in timeline_data],
        "period_days": days,
    }


@router.get("/leads")
async def get_leads(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    status: Optional[str] = None,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get paginated leads list."""
    query = db.query(Lead)

    if status:
        query = query.filter(Lead.status == status)

    total = query.count()
    offset = (page - 1) * limit
    leads = query.order_by(Lead.created_at.desc()).offset(offset).limit(limit).all()

    return {
        "leads": [
            {
                "id": lead.id,
                "user_id": lead.user_id,
                "channel": lead.channel,
                "name": lead.name,
                "email": lead.email,
                "phone": lead.phone,
                "status": lead.status,
                "source_intent": lead.source_intent,
                "created_at": lead.created_at.isoformat(),
            }
            for lead in leads
        ],
        "total": total,
        "page": page,
        "limit": limit,
        "total_pages": (total + limit - 1) // limit,
    }


@router.get("/knowledge")
async def get_knowledge_base(
    page: int = Query(1, ge=1),
    limit: int = Query(20, ge=1, le=100),
    intent: Optional[str] = None,
    status: Optional[str] = None,  # active, inactive, needs-review
    search: Optional[str] = None,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get knowledge base entries with intelligence data."""
    from sqlalchemy import or_
    import json
    
    # For now, use default business_id (can be enhanced with multi-tenant later)
    default_business_id = 1
    
    query = db.query(KnowledgeEntry).filter(KnowledgeEntry.business_id == default_business_id)
    
    # Apply filters
    if intent:
        query = query.filter(KnowledgeEntry.intent == intent)
    if status == "active":
        query = query.filter(KnowledgeEntry.is_active == True)
    elif status == "inactive":
        query = query.filter(KnowledgeEntry.is_active == False)
    if search:
        query = query.filter(
            (KnowledgeEntry.question.ilike(f"%{search}%")) |
            (KnowledgeEntry.answer.ilike(f"%{search}%"))
        )
    
    # Get total count
    total = query.count()
    
    # Apply pagination
    offset = (page - 1) * limit
    entries = query.order_by(KnowledgeEntry.updated_at.desc()).offset(offset).limit(limit).all()
    
    # Get all intents from conversations
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Build response with intelligence data
    result_entries = []
    for entry in entries:
        # Count usage in conversations (simple keyword matching)
        usage_count = 0
        keywords = []
        if entry.keywords:
            try:
                keywords = json.loads(entry.keywords) if isinstance(entry.keywords, str) else entry.keywords
                if keywords and isinstance(keywords, list):
                    # Count conversations with matching keywords
                    usage_count = db.query(func.count(Conversation.id)).filter(
                        Conversation.created_at >= start_date,
                        or_(*[Conversation.user_message.ilike(f"%{kw}%") for kw in keywords[:3]])
                    ).scalar() or 0
            except:
                keywords = []
        
        # Check if entry is linked to intent
        has_intent_link = entry.intent is not None and entry.intent != ""
        
        # Determine quality signals
        quality_signals = []
        if usage_count > 10:
            quality_signals.append("high_performing")
        elif usage_count == 0:
            quality_signals.append("unused")
        if not has_intent_link:
            quality_signals.append("needs_intent_link")
        if entry.is_active == False:
            quality_signals.append("inactive")
        
        # Get last used timestamp (simplified - use updated_at for now)
        last_used = entry.updated_at.isoformat()
        
        result_entries.append({
            "id": entry.id,
            "question": entry.question,
            "answer": entry.answer,
            "keywords": keywords,
            "intent": entry.intent,
            "is_active": entry.is_active,
            "created_at": entry.created_at.isoformat(),
            "updated_at": entry.updated_at.isoformat(),
            # Intelligence data
            "usage_count": usage_count,
            "quality_signals": quality_signals,
            "has_intent_link": has_intent_link,
            "last_used": last_used,
        })
    
    return {
        "entries": result_entries,
        "total": total,
        "page": page,
        "limit": limit,
        "total_pages": (total + limit - 1) // limit,
    }


@router.get("/knowledge/health")
async def get_knowledge_health(
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get knowledge base health and coverage metrics."""
    default_business_id = 1
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Total knowledge entries
    total_entries = db.query(func.count(KnowledgeEntry.id)).filter(
        KnowledgeEntry.business_id == default_business_id
    ).scalar() or 0
    
    # Active entries
    active_entries = db.query(func.count(KnowledgeEntry.id)).filter(
        KnowledgeEntry.business_id == default_business_id,
        KnowledgeEntry.is_active == True
    ).scalar() or 0
    
    # Entries with intent links
    entries_with_intent = db.query(func.count(KnowledgeEntry.id)).filter(
        KnowledgeEntry.business_id == default_business_id,
        KnowledgeEntry.intent.isnot(None),
        KnowledgeEntry.intent != ""
    ).scalar() or 0
    
    # Get all intents from conversations
    conversation_intents = db.query(Conversation.intent).filter(
        Conversation.created_at >= start_date
    ).distinct().all()
    all_intents = [intent[0] for intent in conversation_intents if intent[0] and intent[0] != "unknown"]
    
    # Get intents with knowledge entries
    knowledge_intents = db.query(KnowledgeEntry.intent).filter(
        KnowledgeEntry.business_id == default_business_id,
        KnowledgeEntry.intent.isnot(None),
        KnowledgeEntry.intent != ""
    ).distinct().all()
    knowledge_intent_list = [intent[0] for intent in knowledge_intents]
    
    # Intents without knowledge
    intents_without_knowledge = [intent for intent in all_intents if intent not in knowledge_intent_list]
    
    return {
        "total_entries": total_entries,
        "active_entries": active_entries,
        "entries_with_intent": entries_with_intent,
        "intents_without_knowledge": intents_without_knowledge,
        "unused_entries_count": 0,  # Would need more complex logic
        "coverage_percentage": round((len(knowledge_intent_list) / max(len(all_intents), 1)) * 100, 1) if all_intents else 100,
    }


@router.get("/knowledge/mapping")
async def get_intent_knowledge_mapping(
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get intent to knowledge entry mapping."""
    default_business_id = 1
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Get all intents from conversations
    conversation_intents = db.query(Conversation.intent, func.count(Conversation.id).label("count")).filter(
        Conversation.created_at >= start_date
    ).group_by(Conversation.intent).all()
    
    # Get all knowledge entries
    knowledge_entries = db.query(KnowledgeEntry).filter(
        KnowledgeEntry.business_id == default_business_id
    ).all()
    
    # Build mapping
    mapping = []
    for intent, count in conversation_intents:
        if intent and intent != "unknown":
            linked_entries = [entry for entry in knowledge_entries if entry.intent == intent]
            mapping.append({
                "intent": intent,
                "conversation_count": count,
                "knowledge_entries": [
                    {
                        "id": entry.id,
                        "question": entry.question,
                        "is_active": entry.is_active,
                    }
                    for entry in linked_entries
                ],
                "has_coverage": len(linked_entries) > 0,
            })
    
    return {
        "mapping": mapping,
    }


@router.get("/knowledge/{entry_id}")
async def get_knowledge_entry_detail(
    entry_id: int,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get detailed knowledge entry with usage data."""
    default_business_id = 1
    from sqlalchemy import or_
    import json
    
    entry = db.query(KnowledgeEntry).filter(
        KnowledgeEntry.id == entry_id,
        KnowledgeEntry.business_id == default_business_id
    ).first()
    
    if not entry:
        raise HTTPException(status_code=404, detail="Knowledge entry not found")
    
    start_date = datetime.utcnow() - timedelta(days=30)
    
    # Get usage timeline
    keywords = []
    if entry.keywords:
        try:
            keywords = json.loads(entry.keywords) if isinstance(entry.keywords, str) else entry.keywords
        except:
            pass
    
    # Get conversations with matching keywords
    usage_timeline = []
    if keywords and isinstance(keywords, list):
        for keyword in keywords[:5]:
            conversations = db.query(Conversation).filter(
                Conversation.user_message.ilike(f"%{keyword}%"),
                Conversation.created_at >= start_date
            ).order_by(Conversation.created_at.desc()).limit(10).all()
            
            for conv in conversations:
                usage_timeline.append({
                    "type": "used_in_conversation",
                    "timestamp": conv.created_at.isoformat(),
                    "conversation_id": conv.id,
                    "user_message": conv.user_message[:100],
                    "matched_keyword": keyword,
                })
    
    # Sort by timestamp
    usage_timeline.sort(key=lambda x: x["timestamp"], reverse=True)
    
    return {
        "entry": {
            "id": entry.id,
            "question": entry.question,
            "answer": entry.answer,
            "keywords": keywords,
            "intent": entry.intent,
            "is_active": entry.is_active,
            "created_at": entry.created_at.isoformat(),
            "updated_at": entry.updated_at.isoformat(),
        },
        "usage_timeline": usage_timeline[:20],
    }

